{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#เดะลองรันwith A100 Gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "import pandas as pd \n",
    "import json\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import requests\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def ReturnJsonFormat(Text_Json_format):\n",
    "    # Text_Json = \"{\" + Text_Json_format + \"}\"\n",
    "    Text_Json = Text_Json_format.replace(\"'\",'\"').replace('[','}').replace(']','}')\n",
    "    # print(Text_Json)\n",
    "    return json.loads(Text_Json)\n",
    "\n",
    "#OpenThaiGPT-70b\n",
    "#==================================================================================================\n",
    "# model_path=\"openthaigpt/openthaigpt-1.0.0-70b-chat\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True, torch_dtype=torch.float16)\n",
    "# model.to(device)\n",
    "\n",
    "# def QueryLLM(Prompt,device='cuda',JsonFormat=False):\n",
    "#     inputs = tokenizer.encode(Prompt, return_tensors=\"pt\")\n",
    "#     inputs = inputs.to(device)\n",
    "#     outputs = model.generate(inputs, max_length=512, num_return_sequences=1)\n",
    "#     Answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "#     if JsonFormat:\n",
    "#         Answer = ReturnJsonFormat(Answer)\n",
    "#     return Answer\n",
    "#==================================================================================================\n",
    "\n",
    "def QueryTyphoon_70b(Prompt,device='cuda',JsonFormat=False):\n",
    "    endpoint = 'https://api.opentyphoon.ai/v1/chat/completions'\n",
    "    res = requests.post(endpoint, json={\n",
    "        \"model\": \"typhoon-v1.5x-70b-instruct\",\n",
    "        \"max_tokens\": 512,\n",
    "        \"messages\":  [{\"content\": Prompt ,\"role\":\"user\"}],\n",
    "        \"temperature\": 0.3,\n",
    "        \"top_p\": 0.9,\n",
    "        \"top_k\": 0,\n",
    "        \"repetition_penalty\": 1.05,\n",
    "        \"min_p\": 0\n",
    "    }, headers={\n",
    "        \"Authorization\": \"Bearer sk-GJSNUB7gZTUIwXCkAX2zkJJeaMhwDBcHjz2xt63jW3u9xKEu\",\n",
    "    })\n",
    "    data = res.json()\n",
    "    queries = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "    queries = queries.replace(\"%d.\",\"\")\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Number 1 Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a planner teacher for student learning. The Student want to learn how to create a chat gpt. So Create a guideline that he should study skill or knowledge before create a chat gpt \n",
      "write the Answer in the Json format and English Language \n",
      "\n",
      "'Learning1' : ['Topic' :'q1',\n",
      "                    'detail' : 'd1'\n",
      "                ],\n",
      "                    \n",
      "'Learning2' : 'Topic' :'q2',\n",
      "                'detail' : 'd2'\n",
      "                ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create content \n",
    "Topic = \"create a chat gpt\"\n",
    "Prompt_Task1 = f\"\"\"You are a planner teacher for student learning. The Student want to learn how to {Topic}. So Create a guideline that he should study skill or knowledge before {Topic} \n",
    "write the Answer in the Json format and English Language \n",
    "\n",
    "'Learning1' : ['Topic' :'q1',\n",
    "                    'detail' : 'd1'\n",
    "                ],\n",
    "                    \n",
    "'Learning2' : 'Topic' :'q2',\n",
    "                'detail' : 'd2'\n",
    "                ]\n",
    "\"\"\"\n",
    "print(Prompt_Task1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Return date frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>detail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Python Programming</td>\n",
       "      <td>Understanding of Python programming language, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Natural Language Processing (NLP) Basics</td>\n",
       "      <td>Familiarity with NLP concepts such as tokeniza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Machine Learning Fundamentals</td>\n",
       "      <td>Knowledge of machine learning basics, includin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transformer Architecture</td>\n",
       "      <td>Understanding of the transformer architecture,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hugging Face Transformers Library</td>\n",
       "      <td>Proficiency in using the Hugging Face Transfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dataset Preparation and Preprocessing</td>\n",
       "      <td>Skills in preparing and preprocessing datasets...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Model Training and Fine-tuning</td>\n",
       "      <td>Ability to train and fine-tune GPT models usin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Model Evaluation and Testing</td>\n",
       "      <td>Understanding of how to evaluate and test chat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Deployment and Integration</td>\n",
       "      <td>Knowledge of deploying trained models in produ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Topic  \\\n",
       "0                        Python Programming   \n",
       "1  Natural Language Processing (NLP) Basics   \n",
       "2             Machine Learning Fundamentals   \n",
       "3                  Transformer Architecture   \n",
       "4         Hugging Face Transformers Library   \n",
       "5     Dataset Preparation and Preprocessing   \n",
       "6            Model Training and Fine-tuning   \n",
       "7              Model Evaluation and Testing   \n",
       "8                Deployment and Integration   \n",
       "\n",
       "                                              detail  \n",
       "0  Understanding of Python programming language, ...  \n",
       "1  Familiarity with NLP concepts such as tokeniza...  \n",
       "2  Knowledge of machine learning basics, includin...  \n",
       "3  Understanding of the transformer architecture,...  \n",
       "4  Proficiency in using the Hugging Face Transfor...  \n",
       "5  Skills in preparing and preprocessing datasets...  \n",
       "6  Ability to train and fine-tune GPT models usin...  \n",
       "7  Understanding of how to evaluate and test chat...  \n",
       "8  Knowledge of deploying trained models in produ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Content_json_task1 = QueryLLM(Prompt_Task1,JsonFormat=True)\n",
    "answer_task1 = QueryTyphoon_70b(Prompt_Task1,JsonFormat=True)\n",
    "queries = ReturnJsonFormat(answer_task1)\n",
    "df = pd.DataFrame([\n",
    "    {\"Topic\": q_info['Topic'],\"detail\": q_info['detail']}\n",
    "    for q_key, q_info in queries.items()\n",
    "])\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Number 2 10 Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a greatest teacher for create 10 exercises, Your work to create a 10 question for test student who plan to create a chat gpt to Level measurement knowledge of this student that what level there he is\n",
      "write the Answer only in the Json format and English Language \n",
      "[\n",
      "'Question1' : ['Question' : (q1),\n",
      "                    'Choice' : [\n",
      "                        'Choice1' : (c1),\n",
      "                        'Choice2' : (c2),\n",
      "                        'Choice3' : (c3),\n",
      "                        'Choice4' : (c4)\n",
      "                    ]],\n",
      "                    \n",
      "'Question2' : ['Question' : (q2),\n",
      "                    'Choice' : [\n",
      "                        'Choice1' : (c1),\n",
      "                        'Choice2' : (c2),\n",
      "                        'Choice3' : (c3),\n",
      "                        'Choice4' : (c4)\n",
      "                    ]],\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#generate 10 question \n",
    "Topic = \"create a chat gpt\"\n",
    "Prompt_Task2 = f\"\"\"\n",
    "You are a greatest teacher for create 10 exercises, Your work to create a 10 question for test student who plan to {Topic} to Level measurement knowledge of this student that what level there he is\n",
    "write the Answer only in the Json format and English Language \n",
    "[\n",
    "'Question1' : ['Question' : (q1),\n",
    "                    'Choice' : [\n",
    "                        'Choice1' : (c1),\n",
    "                        'Choice2' : (c2),\n",
    "                        'Choice3' : (c3),\n",
    "                        'Choice4' : (c4)\n",
    "                    ]],\n",
    "                    \n",
    "'Question2' : ['Question' : (q2),\n",
    "                    'Choice' : [\n",
    "                        'Choice1' : (c1),\n",
    "                        'Choice2' : (c2),\n",
    "                        'Choice3' : (c3),\n",
    "                        'Choice4' : (c4)\n",
    "                    ]],\n",
    "]\n",
    "\"\"\"\n",
    "print(Prompt_Task2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 10 questions to test a student's knowledge on creating a chat GPT:\n",
      "\n",
      "[\n",
      "    {\n",
      "        \"Question\": \"What is the primary function of a chat GPT?\",\n",
      "        \"Choices\": {\n",
      "            \"Choice1\": \"To generate images\",\n",
      "            \"Choice2\": \"To process natural language inputs\",\n",
      "            \"Choice3\": \"To make phone calls\",\n",
      "            \"Choice4\": \"To play games\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"Question\": \"Which of the following is NOT a type of GPT model?\",\n",
      "        \"Choices\": {\n",
      "            \"Choice1\": \"Transformer\",\n",
      "            \"Choice2\": \"Recurrent Neural Network (RNN)\",\n",
      "            \"Choice3\": \"Convolutional Neural Network (CNN)\",\n",
      "            \"Choice4\": \"Decision Tree\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"Question\": \"What is the main advantage of using a GPT model for chatbots?\",\n",
      "        \"Choices\": {\n",
      "            \"Choice1\": \"Faster response time\",\n",
      "            \"Choice2\": \"Ability to handle multiple languages\",\n",
      "            \"Choice3\": \"Improved contextual understanding\",\n",
      "            \"Choice4\": \"Reduced memory usage\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"Question\": \"Which library is commonly used for implementing GPT models?\",\n",
      "        \"Choices\": {\n",
      "            \"Choice1\": \"TensorFlow\",\n",
      "            \"Choice2\": \"PyTorch\",\n",
      "            \"Choice3\": \"Keras\",\n",
      "            \"Choice4\": \"Scikit-learn\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"Question\": \"What is tokenization in the context of GPT models?\",\n",
      "        \"Choices\": {\n",
      "            \"Choice1\": \"The process of converting text into numerical representations\",\n",
      "            \"Choice2\": \"The process of generating responses to user input\",\n",
      "            \"Choice3\": \"The process of training a GPT model\",\n",
      "            \"Choice4\": \"The process of fine-tuning a pre-trained GPT model\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"Question\": \"What is the purpose of fine-tuning a pre-trained GPT model?\",\n",
      "        \"Choices\": {\n",
      "            \"Choice1\": \"To improve its performance on a specific task\",\n",
      "            \"Choice2\": \"To reduce its memory usage\",\n",
      "            \"Choice3\": \"To increase its response time\",\n",
      "            \"Choice4\": \"To enable it to handle multiple languages\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"Question\": \"Which of the following is a common application of chat GPTs?\",\n",
      "        \"Choices\": {\n",
      "            \"Choice1\": \"\n"
     ]
    }
   ],
   "source": [
    "answer_task2 = QueryTyphoon_70b(Prompt_Task2,JsonFormat=True)\n",
    "print(answer_task2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return Result w/ Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 1 column 2 (char 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m answer_task2 \u001b[38;5;241m=\u001b[39m QueryTyphoon_70b(Prompt_Task2,JsonFormat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m answer_task2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m answer_task2 \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m queries_task2 \u001b[38;5;241m=\u001b[39m \u001b[43mReturnJsonFormat\u001b[49m\u001b[43m(\u001b[49m\u001b[43manswer_task2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([\n\u001b[0;32m      6\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: q_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuestion\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mq_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChoice\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m q_key, q_info \u001b[38;5;129;01min\u001b[39;00m queries_task2\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m      8\u001b[0m ])\n\u001b[0;32m      9\u001b[0m df\n",
      "Cell \u001b[1;32mIn[6], line 14\u001b[0m, in \u001b[0;36mReturnJsonFormat\u001b[1;34m(Text_Json_format)\u001b[0m\n\u001b[0;32m     12\u001b[0m Text_Json \u001b[38;5;241m=\u001b[39m Text_Json_format\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# print(Text_Json)\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mText_Json\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\envs\\gpu_02\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\envs\\gpu_02\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\envs\\gpu_02\\Lib\\json\\decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m \n\u001b[0;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)"
     ]
    }
   ],
   "source": [
    "# Question_Json_Format = QueryLLM(Prompt_Task2,JsonFormat=True)\n",
    "answer_task2 = \"{\" + answer_task2 + \"}\"\n",
    "queries_task2 = ReturnJsonFormat(answer_task2)\n",
    "df = pd.DataFrame([\n",
    "    {\"Question\": q_info['Question'], **q_info['Choice']}\n",
    "    for q_key, q_info in queries_task2.items()\n",
    "])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Number 3 Possible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a greatest planner teacher for student learning. The student want to learn to create a chat gpt in 24 hour.\n",
      "So tell me this student is possible to  learn this skill in 24 hour.\n",
      "All Answer ill write in Json format\n",
      "Answer In Text Format. Like 'Possible' or 'Impossible'and Answer in \"Possible_or_not\" \n",
      "When answer is 'impossible' add the reason why and Answer in \"Reason\" \n",
      "When answer is 'impossible' make a choice to let's student choose another path to achieve the goal and Answer in \"Choice_Path\" \n",
      "[\n",
      "'Possible_or_not' : ($'Possible' or 'Impossible'),\n",
      "'Reason' : (Reason),\n",
      "'Choice_Path' : [\n",
      "    'Path1' : (Path1),\n",
      "    'Path2' : (Path2),\n",
      "    'Path3' : (Path3),\n",
      "    'Path4' : (Path4) \n",
      "    ]\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Possible / Impossible และ มีเส้นทางให้userเลือก\n",
    "Persona = \"greatest planner teacher for student learning\"\n",
    "Topic = \"create a chat gpt\" #=====================================\n",
    "Time = \"24 hour\"\n",
    "\n",
    "Prompt_Task3 = f\"\"\"You are a {Persona}. The student want to learn to {Topic} in {Time}.\n",
    "So tell me this student is possible to  learn this skill in {Time}.\n",
    "All Answer ill write in Json format\n",
    "Answer In Text Format. Like 'Possible' or 'Impossible'and Answer in \"Possible_or_not\" \n",
    "When answer is 'impossible' add the reason why and Answer in \"Reason\" \n",
    "When answer is 'impossible' make a choice to let's student choose another path to achieve the goal and Answer in \"Choice_Path\" \n",
    "[\n",
    "'Possible_or_not' : ($'Possible' or 'Impossible'),\n",
    "'Reason' : (Reason),\n",
    "'Choice_Path' : [\n",
    "    'Path1' : (Path1),\n",
    "    'Path2' : (Path2),\n",
    "    'Path3' : (Path3),\n",
    "    'Path4' : (Path4) \n",
    "    ]\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print(Prompt_Task3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Possible_or_not</th>\n",
       "      <th>Reason</th>\n",
       "      <th>Path1</th>\n",
       "      <th>Path2</th>\n",
       "      <th>Path3</th>\n",
       "      <th>Path4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Impossible</td>\n",
       "      <td>Creating a fully functional chat GPT in 24 hou...</td>\n",
       "      <td>Focus on learning the basics of NLP and machin...</td>\n",
       "      <td>Use existing chatbot platforms or libraries (e...</td>\n",
       "      <td>Learn how to use pre-trained GPT models (e.g.,...</td>\n",
       "      <td>Collaborate with others who have experience in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Possible_or_not                                             Reason  \\\n",
       "0      Impossible  Creating a fully functional chat GPT in 24 hou...   \n",
       "\n",
       "                                               Path1  \\\n",
       "0  Focus on learning the basics of NLP and machin...   \n",
       "\n",
       "                                               Path2  \\\n",
       "0  Use existing chatbot platforms or libraries (e...   \n",
       "\n",
       "                                               Path3  \\\n",
       "0  Learn how to use pre-trained GPT models (e.g.,...   \n",
       "\n",
       "                                               Path4  \n",
       "0  Collaborate with others who have experience in...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Possbile_Json_Format = QueryLLM(Prompt_Task3)\n",
    "Possbile = QueryTyphoon_70b(Prompt_Task3)\n",
    "Possbile = Possbile.replace('[','{').replace(']','}').replace(\"'\",'\"')\n",
    "Texts = json.loads(Possbile)\n",
    "df = pd.DataFrame([{\n",
    "    \"Possible_or_not\": Texts['Possible_or_not'],\n",
    "    \"Reason\": Texts['Reason'],\n",
    "    **Texts['Choice_Path']\n",
    "}])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
