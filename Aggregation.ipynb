{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#เดะลองรันwith L4 Gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import pandas as pd \n",
    "import json\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def ReturnJsonFormat(Text_Json_format):\n",
    "    Text_Json = \"{\" + Text_Json_format + \"}\"\n",
    "    Text_Json = Text_Json.replace(\"'\",'\"').replace('[','}').replace(']','}')\n",
    "    # print(Text_Json)\n",
    "    return json.loads(Text_Json)\n",
    "\n",
    "\n",
    "model_path=\"openthaigpt/openthaigpt-1.0.0-70b-chat\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True, torch_dtype=torch.float16)\n",
    "model.to(device)\n",
    "# print(model.par)\n",
    "\n",
    "\n",
    "def QueryLLM(Prompt,device='cuda',JsonFormat=False):\n",
    "    inputs = tokenizer.encode(Prompt, return_tensors=\"pt\")\n",
    "    inputs = inputs.to(device)\n",
    "    outputs = model.generate(inputs, max_length=512, num_return_sequences=1)\n",
    "    Answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    if JsonFormat:\n",
    "        Answer = ReturnJsonFormat(Answer)\n",
    "    return Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Number 1 Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create content \n",
    "Topic = \"create a chat gpt\"\n",
    "Prompt_Task1 = f\"\"\"You are a planner teacher for student learning. The Student want to learn how to {Topic}. So Create a guideline that he should study skill or knowledge before {Topic} \n",
    "write the Answer in the Json format and English Language \n",
    "\n",
    "'Learning1' : ['Topic' :'q1',\n",
    "                    'detail' : 'd1'\n",
    "                ],\n",
    "                    \n",
    "'Learning2' : 'Topic' :'q2',\n",
    "                'detail' : 'd2'\n",
    "                ]\n",
    "\"\"\"\n",
    "print(Prompt_Task1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Return date frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Content_json_task1 = QueryLLM(Prompt_Task1,JsonFormat=True)\n",
    "df = pd.DataFrame([\n",
    "    {\"Topic\": q_info['Topic'],\"detail\": q_info['detail']}\n",
    "    for q_key, q_info in Content_json_task1.items()\n",
    "])\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Number 2 10 Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate 10 question \n",
    "Topic = \"create 10 question about chemistry\"\n",
    "\n",
    "Prompt_Task2 = f\"\"\"you are chem teacher who create exam for secondary student  {Topic}. So Create a guideline what should he learning for {Topic} so create chemistry quiz about org chem for secondary student\n",
    "write the Answer in the Json format and English Language \n",
    "\n",
    "'Question1' : ['Question' :'q1',\n",
    "                    'Choice' : [\n",
    "                        'Choice1' : 'q1',\n",
    "                        'Choice2' : 'q1',\n",
    "                        'Choice3' : 'q1',\n",
    "                        'Choice4' : 'q1'\n",
    "                    ]],\n",
    "                    \n",
    "    'Question2' : ['Question' :'q2',\n",
    "                    'Choice' : [\n",
    "                        'Choice1' : 'q2',\n",
    "                        'Choice2' : 'q2',\n",
    "                        'Choice3' : 'q2',\n",
    "                        'Choice4' : 'q2'\n",
    "                    ]]\n",
    "\"\"\"\n",
    "print(Prompt_Task2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return Result w/ Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Question_Json_Format = QueryLLM(Prompt_Task2,JsonFormat=True)\n",
    "df = pd.DataFrame([\n",
    "    {\"Question\": q_info['Question'], **q_info['Choice']}\n",
    "    for q_key, q_info in Question_Json_Format.items()\n",
    "])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Number 3 Possible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Possible / Impossible และ มีเส้นทางให้userเลือก\n",
    "Persona = \"greatest planner teacher for student learning\"\n",
    "Topic = \"create chatGPT\" #=====================================\n",
    "Time = \"24 hour\"\n",
    "\n",
    "Prompt_Task3 = f\"\"\"You are a {Persona}. The student want to learn to {Topic} in {Time}.\n",
    "So tell me this student is possible to  learn this skill in {Time}.\n",
    "Answer In Text Format. Like 'Possible' or 'Impossible' \n",
    " When answer is 'impossible' add the reason why and answer in format\n",
    " Reason : [Reason] \n",
    " When answer is 'impossible' make a choice to let's student choose another path to achieve the goal in format.\n",
    "\n",
    " 'or you can choose another path'\n",
    " Path1 : [Path1]\n",
    " Path2 : [Path2]\n",
    " Path3 : [Path3]\n",
    " Path4 : [Path4]\n",
    " ...\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print(Prompt_Task3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Possbile_Json_Format = QueryLLM(Prompt_Task3)\n",
    "Possbile_Json_Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
